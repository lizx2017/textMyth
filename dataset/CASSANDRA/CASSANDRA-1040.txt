Summary:
read failure during flush
Description:
Joost Ouwerkerk writes:
On a single-node cassandra cluster with basic config (-Xmx:1G)
loop {
insert 5,000 records in a single columnfamily with UUID keys and
random string values (between 1 and 1000 chars) in 5 different columns
spanning two different supercolumns
delete all the data by iterating over the rows with
get_range_slices(ONE) and calling remove(QUORUM) on each row id
returned (path containing only columnfamily)
count number of non-tombstone rows by iterating over the rows
with get_range_slices(ONE) and testing data. Break if not zero.
}
while this is running, call "bin/nodetool -h localhost -p 8081 flush KeySpace" in the background every minute or so. When the data hits some critical size, the loop will break.
Status:
RESOLVED
Priority:
Urgent
Resolution:
Fixed
Affects_version:

Fix_version:
0.7 beta 1
Component:
None
Label:
None
Environment:

Attachment number:
0
Assignee:
Jonathan Ellis
Reporter:
Jonathan Ellis
Create date:
30/Apr/10 13:33
Update date:
16/Apr/19 09:33
Resolved date:
07/May/10 21:31
