Summary:
SimpleSpanFragmenter fails to start a new fragment
Description:
SimpleSpanFragmenter fails to identify a new fragment when there is more than one stop word after a span is detected. This problem can be observed when the Query contains a PhraseQuery.
The problem is that the span extends toward the end of the TokenGroup. This is because waitForProps = positionSpans.get.end + 1; and position += posIncAtt.getPositionIncrement(); this generates a value of position greater than the value of waitForProps and (waitForPos == position) never matches.
SimpleSpanFragmenter.java
  public boolean isNewFragment() {
    position += posIncAtt.getPositionIncrement();

    if (waitForPos == position) {
      waitForPos = -1;
    } else if (waitForPos != -1) {
      return false;
    }

    WeightedSpanTerm wSpanTerm = queryScorer.getWeightedSpanTerm(termAtt.term());

    if (wSpanTerm != null) {
      List<PositionSpan> positionSpans = wSpanTerm.getPositionSpans();

      for (int i = 0; i < positionSpans.size(); i++) {
        if (positionSpans.get(i).start == position) {
          waitForPos = positionSpans.get(i).end + 1;
          break;
        }
      }
    }
   ...
An example is provided in the test case for the following Document and the query "all tokens" followed by the words of a.
Document
"Attribute instances are reused for all tokens of a document. Thus, a TokenStream/-Filter needs to update the appropriate Attribute(s) in incrementToken(). The consumer, commonly the Lucene indexer, consumes the data in the Attributes and then calls incrementToken() again until it retuns false, which indicates that the end of the stream was reached. This means that in each call of incrementToken() a TokenStream/-Filter can safely overwrite the data in the Attribute instances."
HighlighterTest.java
 public void testSimpleSpanFragmenter() throws Exception {

    ...

    doSearching("\"all tokens\"");

    maxNumFragmentsRequired = 2;
    
    scorer = new QueryScorer(query, FIELD_NAME);
    highlighter = new Highlighter(this, scorer);

    for (int i = 0; i < hits.totalHits; i++) {
      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);
      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));

      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 20));

      String result = highlighter.getBestFragments(tokenStream, text,
          maxNumFragmentsRequired, "...");
      System.out.println("\t" + result);

    }
  }
Result
are reused for <B>all</B> <B>tokens</B> of a document. Thus, a TokenStream/-Filter needs to update the appropriate Attribute(s) in incrementToken(). The consumer, commonly the Lucene indexer, consumes the data in the Attributes and then calls incrementToken() again until it retuns false, which indicates that the end of the stream was reached. This means that in each call of incrementToken() a TokenStream/-Filter can safely overwrite the data in the Attribute instances.
Expected Result
for <B>all</B> <B>tokens</B> of a document
Status:
CLOSED
Priority:
Minor
Resolution:
Fixed
Affects_version:
None
Fix_version:
5.4.1, 5.5
Component:
modules/highlighter
Label:
None
Environment:

Attachment number:
0
Assignee:
David Smiley
Reporter:
Elmer Garduno
Create date:
20/Jan/10 23:01
Update date:
26/Jan/16 08:47
Resolved date:
29/Dec/15 22:03
