Summary:
StandardAnalyzer/Tokenizer.setMaxTokenLength's javadocs are lying
Description:
The javadocs claim that too-long tokens are discarded, but in fact they are simply chopped up. The following test case unexpectedly passes:
  public void testMaxTokenLengthNonDefault() throws Exception {
    StandardAnalyzer a = new StandardAnalyzer();
    a.setMaxTokenLength(5);
    assertAnalyzesTo(a, "ab cd toolong xy z", new String[]{"ab", "cd", "toolo", "ng", "xy", "z"});
    a.close();
  }
We should at least fix the javadocs ...
(I hit this because I was trying to also add setMaxTokenLength to EnglishAnalyzer).
Status:
CLOSED
Priority:
Major
Resolution:
Fixed
Affects_version:
None
Fix_version:
6.6, 7.0
Component:
None
Label:
None
Environment:

Attachment number:
0
Assignee:
Michael McCandless
Reporter:
Michael McCandless
Create date:
30/Mar/17 09:58
Update date:
08/Jun/17 23:26
Resolved date:
11/Apr/17 19:41
