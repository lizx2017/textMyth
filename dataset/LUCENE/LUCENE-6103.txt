Summary:
StandardTokenizer doesn't tokenize word:word
Description:
StandardTokenizer (and by result most default analyzers) will not tokenize word:word and will preserve it as one token. This can be easily seen using Elasticsearch's analyze API:
localhost:9200/_analyze?tokenizer=standard&text=word%20word:word
If this is the intended behavior, then why? I can't really see the logic behind it.
If not, I'll be happy to join in the effort of fixing this.
Status:
RESOLVED
Priority:
Major
Resolution:
Not A Problem
Affects_version:
4.9
Fix_version:
None
Component:
modules/analysis
Label:
None
Environment:

Attachment number:
0
Assignee:
Steve Rowe
Reporter:
Itamar Syn-Hershko
Create date:
09/Dec/14 17:21
Update date:
10/Dec/14 16:19
Resolved date:
09/Dec/14 18:08
